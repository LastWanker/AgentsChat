当前：
索引区（检索/回忆）：决定要回忆哪些事件。
起草区（Draft）：写个初稿，表达“我想说什么”。
成文区（Final）：补齐引用、打上权重，输出正式内容。
reference 选取逻辑分析
当前逻辑（简化版）
Draft 里写好 retrieval_plan。
ReferenceResolver 根据 plan 抓取事件。
Finalizer 把候选引用套上 weight。


————————Draft阶段————————

1：索引计划的生成
当前的索引是简单的向前就近浏览事件内容，然后再draft阶段生成检索计划“retrieval_plan”，
然后ReferenceResolver 根据 plan 抓取事件。最后在finalize阶段，参考被抓取的事件，生成发言、引用和权重。
但首先：
    为了生成检索计划，在draft阶段，就近观察最近的n个事件内容没问题；就语义而言，这是看看现在大家在讨论什么。
    这是正确策略。但不能仅仅是这样。
    1.还要参考个人事务表【new】。（这对llm来说是一个软参考，为生成文字的上下文记忆程度服务，不会绑架agent行为。）
    【个人事务表】每个agent也要被系统维护一张（两块）自己的个人事务表，这张表应该也被存储，方便调用。事务表动态更新，内容为在本次session中：
        1.DoneList:我曾做了什么。
            （列表每一项为：Memory化（T/F）＋来源agent_di(这里一直是自己)+根事件event_id(单个或3元组)+一句话总结做了什么。只能增加。
            update时机1：（agent_id = self.agent_id）的event表更新之后生成。
            生成者：并行且事后的llm系统。
            update时机2：（if Memory化False数量的表项达到9条）自动总结其中任意（3条/9条）最为相关的，合称归纳为1条Memory化True的表项，True表示只读。event_id是3个。
            生成者：并行且事后的llm系统。
        2.TodoList:我被要求做什么。
            （列表每一项为：来源agent_di+根事件event_id＋一句话总结被要求了什么。
            update时机1：（agent_id != self.agent_id）的event表更新之后生成。
            生成并分发到每个相关agent的机构：并行且事后的llm系统
            逻辑：llm观察一个符合条件的event，保守生成诸如“1.name+id要求name：什么事(也就是存储里的“一句话”);2……”这种简单schema,利用这个schema进行分发更新）
            update时机2：（agent_id = self.agent_id）的event表更新之后直接删除并转移到Donelist
            判断者：并行且事后的llm系统。
            逻辑：llm观察一个符合条件的event以及该agent的个人事务表.work保守判断该event“完成了本agent的个人事务表.work里面的某项number.n”这种简单schema）
    2.为了生成检索计划，还要参考全tag池【new】
    【tags池】
        1.每个event新增属性tags，比如：{"agent_name","agent领域","系统","安全","稳定",…}。暂时固定前两个为agent个人要素。不超过9个，在中文中，一般只支持最小语素，禁止劣质语素生成，比如“的”。
        2.tags如何生成：由于时效性，也就是事件生成后可能立刻就被参考，因而本事件的tags首先由finalize阶段生成，不超过6个。
        3.event表更新后，触发并行且事后的llm系统维护每个event的tags，从原本的tag忽略的角度，扩充至9个。允许从0个开始扩充。
        4.机械地维护一个本次session专属的tag池，也是应该被存储的结构。一旦events存储表被更新，则补充没被收录的tags。
        5.机械地维护tag池：每个tag词条后面应该跟着一个索引表，内容是包含本tag的事件id列表。
        6.在seed事件产生后，系统应该根据此事件初始化tag池，使其中有9个关键词。然后再开始下一轮。仅此时有这个限制，平时，都并行维护。
    【如何使用tags池？】
        1.draft阶段应该生成索引需要的tags(也就是目前draft里面的“关键词”)应该直接从tags中直接选取，虽然推荐6个左右，但是数量上限可以很高，不超过12个即可。
        2.其次，允许draft生成不在tags池里面的关键词，这里直接进行面向全部文本的按文本索引。
        3.保留最近几条策略等等以往策略，但是最近几条数量削减为max{6,agent数量*2}。但和目前逻辑不一样的是，取并集。
        4.得到三者对应的event_id取并集。保留scope机制（这是核心机制之一），不符合scope的应该被筛掉。和整体取交集。
             4.1放弃根据索引层数进行检索（因为tag的引入可能导致引用爆发式增长），
             4.2放弃根据event_types进行检索。（这不合理，agent语义上来讲看见什么都可能造成影响）
             4.3放弃limit，向稠密图发展。
        5.以上所有的event_id都应该被存储到events的引用reference列表。这里和原本的策略有冲突，现在应该按照“所有”都进入reference表。
            这里的语义是，无法否认此次llm调用的确基于以上event，即便贡献可能很小或者很大。
            尽管这种操作可能使得最后产生的有向带权引用图变得稠密。
    3.为了生成检索计划，还需要参考由LLM事后维护的一份文本TeamBoard【new】。这份TeamBoard的更新机制如下：
        很简单，每当BOSS发话，由LLM总结，更新一条简短的TeamBoard；每6轮，也就是event总量到6，LLM总结这6条发生了什么，更新一条简短的TeamBoard。
    4.最后，需要支持这些新添项目的索引方法。
    5.需要明确，目前阶段还没引入agent专属知识库系统，而一旦引入，也是需要在draft阶段做筛选，挑出其中一部分来作为最后finalize的语料input。
有了以上语料，我们将：
1.使用个人事务表、TeamBoard、最近n(建议max{6,agent数量*2})条event、tags池（如果有的话则优先从其中取）生成6~12个tags
2.发言稿生成：目前message_plan: draft_text:二者语义重合了。取后者即可。kind生成，依旧与event_type对齐。
3：(confidence,motivation,urgency)三维的生成：应该主要参考TodoList:我被要求做什么；agent人设表（后面有）

然后，在scope范围内，[按照tag得到的所有id进行query的event_id ∪ 最近n(建议max{6,agent数量*2})条event_id ∪ 不在tag池按文本检索到的event_id]
就是我们得到的reference列表，不进行任何剪枝。

————————finalize阶段————————
1.应该参考使用个人事务表.DoneList。至于TodoList，主要是Draft阶段已经使用它生成了本次的发言草稿和意向，不要让它影响了。
2.应该参考agent人设表，这里不能只在prompts里面简单说说了，应该让prompts订好框架，而每个agent人设表单独一个文件，放在config/roles，支持即插即用。
    1.deepseek的API网站明确说: 可以设置temperature参数，默认为1.0
        代码生成/数学解题0.0;数据抽取/分析1.0;通用对话1.3;翻译1.3创意类写作/诗歌创作1.5
        所以，应该想方设法让每个角色的人设文件维持不同的temperature
    2.人设的维度应该有：
        生理维度（年龄，性别，种族）
        心理维度（暂时荣格八维）
        角色背景（可以是假的经历，也可以是模拟一个真实存在的人物，但字数要尽量精简）
        语言语气（简短；热情……）
        擅长（可能会引起confidence和motivation变化）
3.应该使用draft_text。这个应该是主要的、大纲性质的。
4.应该参考TeamBoard。
5.使用reference列表的所有events的内容（除却引用）作为上文。
注意，“参考”的可以不讲究形式，但“使用”的最好按schema排在前面。
llm生成文本，群聊内的直接输出，而非“我打算做什么”。
机械地而非llm地生成继承draft阶段的缺省的references。
根据kind机械地生成是否completed。
不需要candidate_references。
————————event生成后触发的并发维护阶段————————
1.如上所述，维护个人事务表。
2.如上所述，维护tags池。
3.如上所述，按规则维护TeamBoard
4.在进行weight事后【new】评分时，充分利用llm api的并发权限，使用循环【new】为每个维度的每个事件进行事件内容之间的两两打分，
    让输入和输出的内容都相对短小（尤其是输出，只有一个数字。或者，一个数字加一句话判断，但我们不要那句话，以我对llm的理解，这样没准能提高可信度）而不是一次出结果，产生巨量幻觉。
    注意：dependence、inspiration是被引用的event对主体event而言的，而stance是主体event对被引用的态度。
    我们应该给llm设定好打分参照分段表。比如：
        dependence：0完全无关，0.1似有若无，0.2略微相关，0.3轻度关联，0.4有依赖性，0.5明显依赖，0.6较强依赖，0.7核心依赖，0.8核心一致，0.9几乎复述，1完全转述
        inspiration：0毫无启发，0.1似有若无，0.2略微影响，0.3轻度影响，0.4影响思路，0.5贡献明显，0.6较强影响，0.7核心思路，0.8思路一致，0.9按部就班，1完全遵照
        stance：-1完全对立，-0.9难以弥合，-0.8核心对立，-0.7核心冲突，-0.6较强否认，-0.5明显否认，-0.4否认态度，-0.3轻度否认，-0.2略感不对，-0.1将信将疑，0无关对错
                0.1难说是错，0.2勉强认可，0.3轻度认可，0.4大致认可，0.5明确认可，0.6较为赞许，0.7核心相似，0.8核心一致，0.9几乎一致，1完全一致
        我们可以看到，前两者0.5其实也是一个分水岭，两头都是含有贬义的说法。
        特别地，要对llm强调：针对stance，无关立场对错的可以直接置为0。例如，Alice说今天下雨了，Bob说我家今年赚了20万。
    至于原本跟随finalize直接产生的三维的方法，直接砍掉不要了，缺省fault为0.1，0.1，0.1，最后要被替换掉。